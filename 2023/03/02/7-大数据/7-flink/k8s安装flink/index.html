<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/myblog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/myblog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/myblog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/myblog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/myblog/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=EB Garamond:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/myblog/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/myblog/lib/pace/pace-theme-bounce.min.css">
  <script src="/myblog/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"192.168.171.142","root":"/myblog/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="安装介绍由于项目所需，需要从零开始部署flink on kubernetes。项目的生产环境是完全的内网，需要提前下载所有所需的安装包，进行离线安装。我们公司没有人接触过kubernetes，只听说过，之前使用的flink都是flink on yarn，网上找了好多好多安装flink on kubernetes的文档，但几乎全都是在线安装，到处都少步骤，对于初次接触kubernetes的人特别不友">
<meta property="og:type" content="article">
<meta property="og:title" content="k8s部署flink">
<meta property="og:url" content="http://192.168.171.142/myblog/2023/03/02/7-%E5%A4%A7%E6%95%B0%E6%8D%AE/7-flink/k8s%E5%AE%89%E8%A3%85flink/index.html">
<meta property="og:site_name" content="李同学的特殊用法">
<meta property="og:description" content="安装介绍由于项目所需，需要从零开始部署flink on kubernetes。项目的生产环境是完全的内网，需要提前下载所有所需的安装包，进行离线安装。我们公司没有人接触过kubernetes，只听说过，之前使用的flink都是flink on yarn，网上找了好多好多安装flink on kubernetes的文档，但几乎全都是在线安装，到处都少步骤，对于初次接触kubernetes的人特别不友">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://192.168.171.142/myblog/myblog/2023/03/02/7-%E5%A4%A7%E6%95%B0%E6%8D%AE/7-flink/k8s%E5%AE%89%E8%A3%85flink/img.png">
<meta property="article:published_time" content="2023-03-02T00:21:51.000Z">
<meta property="article:modified_time" content="2023-03-02T07:48:44.050Z">
<meta property="article:author" content="秋天以北">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://192.168.171.142/myblog/myblog/2023/03/02/7-%E5%A4%A7%E6%95%B0%E6%8D%AE/7-flink/k8s%E5%AE%89%E8%A3%85flink/img.png">

<link rel="canonical" href="http://192.168.171.142/myblog/2023/03/02/7-%E5%A4%A7%E6%95%B0%E6%8D%AE/7-flink/k8s%E5%AE%89%E8%A3%85flink/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>k8s部署flink | 李同学的特殊用法</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/myblog/rss2.xml" title="李同学的特殊用法" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

   <a target="_blank" rel="noopener" href="https://github.com/XiaoChouYou" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#64CEAA; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/myblog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">李同学的特殊用法</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/myblog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/myblog/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/myblog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/myblog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/myblog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/myblog/resources/" rel="section"><i class="fa fa-object-group fa-fw"></i>资源</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://192.168.171.142/myblog/2023/03/02/7-%E5%A4%A7%E6%95%B0%E6%8D%AE/7-flink/k8s%E5%AE%89%E8%A3%85flink/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myblog/images/avatar.jpg">
      <meta itemprop="name" content="秋天以北">
      <meta itemprop="description" content="君子博学而日叁醒乎己，则知明而行无过矣">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="李同学的特殊用法">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          k8s部署flink
        </h1>

        <div class="post-meta">

          
            <i class="fa fa-thumb-tack"></i>
            <font color=7D26CD>置顶</font>
            <span class="post-meta-divider">|</span>
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-03-02 08:21:51 / 修改时间：15:48:44" itemprop="dateCreated datePublished" datetime="2023-03-02T08:21:51+08:00">2023-03-02</time>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>32k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>29 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="安装介绍"><a href="#安装介绍" class="headerlink" title="安装介绍"></a>安装介绍</h2><p>由于项目所需，需要从零开始部署flink on kubernetes。项目的生产环境是完全的内网，需要提前下载所有所需的安装包，进行离线安装。<br>我们公司没有人接触过kubernetes，只听说过，之前使用的flink都是flink on yarn，网上找了好多好多安装flink on kubernetes的文档，但几乎全都是在线安装，到处都少步骤，对于初次接触kubernetes的人特别不友好，看的人特别蒙。<br>网上的文档由于是在线安装，从头到尾两三个命令，两三个配置文件就搭建上了。然而离线安装和在线安装完全不同，网上的文档甚至都没有标明是在线安装，对于任何东西都要离线安装的我来说，基本没有意识到那些简单的步骤是在线安装，感觉就那么几步就安装好了，感觉不可思议，让我走了很多弯路。<br>离线安装的步骤东拼西凑才凑出来这么一套安装流程。<br>另外，网上flink on kubernetes的文章真的是相当少，遇到了问题想要找到解决方法都得自己想，网上基本没有可以参考的文章。<br>刚开始安装kubernetes时，我用的环境是redhat6.8，由于kubernetes对redhat支持率很低，而且7版本之前的linux安装docker，kubernetes也有很多不可预料的问题，折腾了两三天愣是装不上，所以除非是正在运行的生产环境没有办法更改操作系统，否则强烈建议使用centos7以上的系统安装kubernetes。再一个，现在7版本之前的linux系统已经过时了，现在新增linux服务器主流都在7以上，很多稍微新一点的软件版本都需要7以上的环境。</p>
<span id="more"></span>
<h2 id="二、安装环境"><a href="#二、安装环境" class="headerlink" title="二、安装环境"></a>二、安装环境</h2><h3 id="1-服务器详情"><a href="#1-服务器详情" class="headerlink" title="1.服务器详情"></a>1.服务器详情</h3><table>
<thead>
<tr>
<th>服务器名称</th>
<th>IP地址</th>
<th>操作系统</th>
</tr>
</thead>
<tbody><tr>
<td>vmlinux4</td>
<td>192.168.0.104</td>
<td>Centos7.7</td>
</tr>
<tr>
<td>vmlinux5</td>
<td>192.168.0.105</td>
<td>Centos7.7</td>
</tr>
<tr>
<td>vmlinux6</td>
<td>192.168.0.106</td>
<td>Centos7.7</td>
</tr>
</tbody></table>
<h3 id="2-安装包详情"><a href="#2-安装包详情" class="headerlink" title="2.安装包详情"></a>2.安装包详情</h3><table>
<thead>
<tr>
<th>软件</th>
<th>安装包</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Docker</td>
<td>docker-ce-cli-18.09.9-3.el7.x86_64.rpm</td>
<td>kubernetes依赖</td>
</tr>
<tr>
<td></td>
<td>container-selinux-2.107-3.el7.noarch.rpm</td>
<td>kubernetes依赖</td>
</tr>
<tr>
<td></td>
<td>containerd.io-1.2.6-3.3.el7.x86_64.rpm</td>
<td>kubernetes依赖</td>
</tr>
<tr>
<td></td>
<td>docker-ce-18.09.9-3.el7.x86_64.rpm</td>
<td>kubernetes依赖</td>
</tr>
<tr>
<td>etcd</td>
<td>etcd-v3.3.17-linux-amd64.tar.gz</td>
<td>kubernetes依赖</td>
</tr>
<tr>
<td>kubernetes</td>
<td>kubernetes-node-linux-amd64.tar.gz</td>
<td></td>
</tr>
<tr>
<td></td>
<td>kubernetes-server-linux-amd64.tar.gz</td>
<td></td>
</tr>
<tr>
<td>flannel</td>
<td>flannel-v0.11.0-linux-amd64.tar.gz</td>
<td></td>
</tr>
<tr>
<td>docker-flink镜像</td>
<td>flink:1.7.2</td>
<td>flink-docker镜像包</td>
</tr>
<tr>
<td>pause镜像</td>
<td>pause:3.1</td>
<td>k8s运行所需docker镜像包</td>
</tr>
</tbody></table>
<h2 id="三、安装步骤"><a href="#三、安装步骤" class="headerlink" title="三、安装步骤"></a>三、安装步骤</h2><h3 id="1-安装docker"><a href="#1-安装docker" class="headerlink" title="1.安装docker"></a>1.安装docker</h3><p>kubernetes集群需要docker作为底层，在三台服务器上安装docker<br>docker的安装很简单，只需要下载4个rpm包进行安装即可。<br>不建议使用源码安装，因为已经有这么简单高效的rpm包了，源码安装坑很多，在有rpm包的情况下，使用源码安装很浪费时间<br>只需按顺序安装4个相关包，连环境变量都不用设置，docker环境就部署完毕了</p>
<h4 id="（1）下载安装包"><a href="#（1）下载安装包" class="headerlink" title="（1）下载安装包"></a>（1）下载安装包</h4><p>docker需要4个安装包：<br>docker-ce-cli-18.09.9-3.el7.x86_64.rpm<br>container-selinux-2.107-3.el7.noarch.rpm<br>containerd.io-1.2.6-3.3.el7.x86_64.rpm<br>docker-ce-18.09.9-3.el7.x86_64.rpm<br>将这四个安装包上传到所有3台服务器上<br>下载地址：<br><a target="_blank" rel="noopener" href="https://download.docker.com/linux/centos/7/x86_64/stable/Packages">https://download.docker.com/linux/centos/7/x86_64&#x2F;stable&#x2F;Packages</a><br><a target="_blank" rel="noopener" href="https://centos.pkgs.org/7/centos-extras-x86_64/container-selinux-2.107-3.el7.noarch.rpm.html">https://centos.pkgs.org/7/centos-extras-x86_64&#x2F;container-selinux-2.107-3.el7.noarch.rpm.html</a></p>
<h4 id="（2）安装服务"><a href="#（2）安装服务" class="headerlink" title="（2）安装服务"></a>（2）安装服务</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 docker]# rpm -ivh docker-ce-cli-18.09.9-3.el7.x86_64.rpm </span><br><span class="line">[root@vmlinux4 docker]# rpm -ivh container-selinux-2.107-3.el7.noarch.rpm </span><br><span class="line">[root@vmlinux4 docker]# rpm -ivh containerd.io-1.2.6-3.3.el7.x86_64.rpm </span><br><span class="line">[root@vmlinux4 docker]# rpm -ivh docker-ce-18.09.9-3.el7.x86_64.rpm </span><br></pre></td></tr></table></figure>


<h4 id="（3）启动服务"><a href="#（3）启动服务" class="headerlink" title="（3）启动服务"></a>（3）启动服务</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 docker]# service docker start</span><br><span class="line">Redirecting to /bin/systemctl start docker.service</span><br></pre></td></tr></table></figure>
<p>测试服务</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 docker]# docker version</span><br><span class="line">Client:</span><br><span class="line"> Version:           18.09.9</span><br><span class="line"> API version:       1.39</span><br><span class="line"> Go version:        go1.11.13</span><br><span class="line"> Git commit:        039a7df9ba</span><br><span class="line"> Built:             Wed Sep  4 16:51:21 2019</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Experimental:      false</span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          18.09.9</span><br><span class="line">  API version:      1.39 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.11.13</span><br><span class="line">  Git commit:       039a7df</span><br><span class="line">  Built:            Wed Sep  4 16:22:32 2019</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     false</span><br></pre></td></tr></table></figure>
<p>docker的安装就完成了，在后面flannel的安装中还需要再对docker进行调整，这里先不做修改，在后面进行到相应的步骤时再进行调整</p>
<h3 id="2-安装etcd集群"><a href="#2-安装etcd集群" class="headerlink" title="2.安装etcd集群"></a>2.安装etcd集群</h3><p>kubernetes需要etcd数据库作为底层数据库，需要在所有安装kubernetes的服务器上安装etcd集群，以下是集群的安装方式</p>
<h4 id="（1）下载安装包-1"><a href="#（1）下载安装包-1" class="headerlink" title="（1）下载安装包"></a>（1）下载安装包</h4><p>etcd包下载地址<a target="_blank" rel="noopener" href="https://github.com/etcd-io/etcd/releases/tag/v3.3.17">https://github.com/etcd-io/etcd/releases/tag/v3.3.17</a><br>将安装包分别上传到3个服务器</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux1 ~]# cd /sga/etcd/</span><br><span class="line">[root@vmlinux1 etcd]# ll</span><br><span class="line">total 13896</span><br><span class="line">-rw-r--r--.		1 root   root  14222547 Oct 23 11:08	 etcd-v3.3.17-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h4 id="（2）创建etcd配置文件"><a href="#（2）创建etcd配置文件" class="headerlink" title="（2）创建etcd配置文件"></a>（2）创建etcd配置文件</h4><p>在3台服务器解压安装包，改名，并将etcd etcdctl文件cp到&#x2F;usr&#x2F;bin目录</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux1 etcd]# tar -zxvf etcd-v3.3.17-linux-amd64.tar.gz </span><br><span class="line">[root@vmlinux1 etcd]# ll</span><br><span class="line">total 13896</span><br><span class="line">drwxr-xr-x. 	5 478493 89939     4096 Oct 24 12:13	 etcd-v3.3.17-linux-amd64</span><br><span class="line">-rw-r--r--.		1 root   root  14222547 Oct 23 11:08	 etcd-v3.3.17-linux-amd64.tar.gz</span><br><span class="line">[root@vmlinux1 etcd]# cd etcd-v3.3.17-linux-amd64</span><br><span class="line">[root@vmlinux1 etcd-v3.3.17-linux-amd64]# ll</span><br><span class="line">total 39068</span><br><span class="line">drwx------.	3 	root		root      4096 Oct 24 09:24	default.etcd</span><br><span class="line">drwxr-xr-x.	10 	478493	89939     4096 Oct 12 01:25 	Documentation</span><br><span class="line">-rwxr-xr-x.  	1 	478493	89939 22102784 Oct 12 01:25 	etcd</span><br><span class="line">-rwxr-xr-x.  	1	478493	89939 17770784 Oct 12 01:25 	etcdctl</span><br><span class="line">-rw-r--r--.  	1 	root		root     49109 Oct 24 13:04 	etcd_log.log</span><br><span class="line">-rw-r--r--.  	1 	478493	89939    38864 Oct 12 01:25 	README-etcdctl.md</span><br><span class="line">-rw-r--r--. 	1 	478493	89939     7262 Oct 12 01:25 	README.md</span><br><span class="line">-rw-r--r--. 	1 	478493	89939     7855 Oct 12 01:25 	READMEv2-etcdctl.md</span><br><span class="line">[root@vmlinux1 etcd]# cd ..</span><br><span class="line">[root@vmlinux1 etcd]# mv etcd-v3.3.17-linux-amd64 etcd</span><br><span class="line">[root@vmlinux4 etcd]# cp etcd/etcd etcd/etcdctl /usr/bin/</span><br></pre></td></tr></table></figure>
<p>创建配置文件etcd.conf，这里的配置文件是集群的配置文件，单机的配置文件不同</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 etcd]# cat etcd.conf</span><br><span class="line">ETCD_NAME=&quot;my-etcd-1&quot;</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;</span><br><span class="line">#advertise-client-urls</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.0.104:2379&quot;</span><br><span class="line">#listen-peer-urls</span><br><span class="line">ETCD_LISTEN_PEER_URLS=&quot;http://0.0.0.0:2380&quot;</span><br><span class="line">#initial-advertise-peer-urls</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.0.104:2380&quot;</span><br><span class="line">#initial-cluster-token</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKER=&quot;etcd-cluster-test&quot;</span><br><span class="line">#initial-cluster-state</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</span><br><span class="line">#initial-cluster</span><br><span class="line">ETCD_INITIAL_CLUSTER=&quot;my-etcd-1=http://192.168.0.104:2380,my-etcd-2=http://192.168.0.105:2380,my-etcd-3=http://192.168.0.106:2380&quot;</span><br></pre></td></tr></table></figure>

<h4 id="（3）创建etcd服务文件"><a href="#（3）创建etcd服务文件" class="headerlink" title="（3）创建etcd服务文件"></a>（3）创建etcd服务文件</h4><p>创建etcd启动的服务文件，通过创建服务文件，可以将etcd服务添加到service</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 etcd]# cat /lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">WorkingDirectory=/sga/etcd/etcd</span><br><span class="line">EnvironmentFile=-/sga/etcd/etcd/etcd.conf</span><br><span class="line">ExecStart=/usr/bin/etcd \</span><br><span class="line">        --name=$&#123;ETCD_NAME&#125; \</span><br><span class="line">        --listen-client-urls=$&#123;ETCD_LISTEN_CLIENT_URLS&#125; \</span><br><span class="line">        --advertise-client-urls=$&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \</span><br><span class="line">        --listen-peer-urls=$&#123;ETCD_LISTEN_PEER_URLS&#125; \</span><br><span class="line">        --initial-advertise-peer-urls=$&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \</span><br><span class="line">        --initial-cluster=$&#123;ETCD_INITIAL_CLUSTER&#125; \</span><br><span class="line">        --initial-cluster-token=$&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \</span><br><span class="line">        --initial-cluster-state=$&#123;ETCD_INITIAL_CLUSTER_STATE&#125; \</span><br><span class="line">        --initial-cluster=$&#123;ETCD_INITIAL_CLUSTER&#125;</span><br><span class="line">Type=notify</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<h4 id="（3）启动etcd集群"><a href="#（3）启动etcd集群" class="headerlink" title="（3）启动etcd集群"></a>（3）启动etcd集群</h4><p>创建好两个配置文件，集群就可以启动了<br>分别在三个服务器执行启动命令</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux1 ~]# service etcd start</span><br><span class="line">Redirecting to /bin/systemctl start etcd.service</span><br><span class="line">[root@vmlinux4 etcd]# service etcd status</span><br><span class="line">Redirecting to /bin/systemctl status etcd.service</span><br><span class="line">● etcd.service - Etcd Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/etcd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Wed 2019-11-06 11:11:35 CST; 5 days ago</span><br><span class="line"> Main PID: 74969 (etcd)</span><br><span class="line">    Tasks: 13</span><br><span class="line">   Memory: 467.6M</span><br><span class="line">   CGroup: /system.slice/etcd.service</span><br><span class="line">           └─74969 /usr/bin/etcd --name=my-etcd-1 --listen-client-urls=http://0.0.0.0:2379 --advertise-client-urls=http://192.168.0.104:2379 --listen-peer-urls=http://...</span><br><span class="line"></span><br><span class="line">Nov 12 09:21:48 vmlinux4 etcd[74969]: store.index: compact 1200814</span><br><span class="line">Nov 12 09:21:48 vmlinux4 etcd[74969]: finished scheduled compaction at 1200814 (took 2.652259ms)</span><br><span class="line">Nov 12 09:26:48 vmlinux4 etcd[74969]: store.index: compact 1201233</span><br><span class="line">Nov 12 09:26:48 vmlinux4 etcd[74969]: finished scheduled compaction at 1201233 (took 988.471µs)</span><br><span class="line">Nov 12 09:31:48 vmlinux4 etcd[74969]: store.index: compact 1201650</span><br><span class="line">Nov 12 09:31:48 vmlinux4 etcd[74969]: finished scheduled compaction at 1201650 (took 1.123113ms)</span><br><span class="line">Nov 12 09:36:48 vmlinux4 etcd[74969]: store.index: compact 1202068</span><br><span class="line">Nov 12 09:36:48 vmlinux4 etcd[74969]: finished scheduled compaction at 1202068 (took 935.626µs)</span><br><span class="line">Nov 12 09:41:48 vmlinux4 etcd[74969]: store.index: compact 1202485</span><br><span class="line">Nov 12 09:41:48 vmlinux4 etcd[74969]: finished scheduled compaction at 1202485 (took 910.437µs)</span><br></pre></td></tr></table></figure>
<h4 id="（4）查看etcd集群状态"><a href="#（4）查看etcd集群状态" class="headerlink" title="（4）查看etcd集群状态"></a>（4）查看etcd集群状态</h4><p>启动集群以后，看到如下状态就部署成功了</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux6 etcd]# etcdctl member list</span><br><span class="line">5672fb11ae669168: name=my-etcd-3 peerURLs=http://192.168.0.106:2380 clientURLs=http://192.168.0.106:2379 isLeader=false</span><br><span class="line">5b83ad767f39380a: name=my-etcd-2 peerURLs=http://192.168.0.105:2380 clientURLs=http://192.168.0.105:2379 isLeader=false</span><br><span class="line">e2803f940d8aa43f: name=my-etcd-1 peerURLs=http://192.168.0.104:2380 clientURLs=http://192.168.0.104:2379 isLeader=true</span><br><span class="line"></span><br><span class="line">[root@vmlinux1 ~]# etcdctl cluster-health</span><br><span class="line">member 5672fb11ae669168 is healthy: got healthy result from http://192.168.0.106:2379</span><br><span class="line">member 5b83ad767f39380a is healthy: got healthy result from http://192.168.0.105:2379</span><br><span class="line">member e2803f940d8aa43f is healthy: got healthy result from http://192.168.0.104:2379</span><br><span class="line">cluster is healthy</span><br></pre></td></tr></table></figure>

<h3 id="3-安装kube-apiserver"><a href="#3-安装kube-apiserver" class="headerlink" title="3.安装kube-apiserver"></a>3.安装kube-apiserver</h3><p>第三步到第五步的服务是kubernetes的服务组件，即master端，在服务端（master）安装，我这里的服务端是vmlinux4<br>将下载的两个安装包上传到vmlinux4<br>kubernetes-server-linux-amd64.tar.gz<br>kubernetes-node-linux-amd64.tar.gz</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 kubernetes]# ll</span><br><span class="line">总用量 542448</span><br><span class="line">drwxr-xr-x. 6 root root      4096 10月 31 17:48 kubernetes</span><br><span class="line">-rw-r--r--. 1 root root  14253719 10月 31 17:22 kubernetes-client-linux-amd64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root  14283993 10月 31 17:22 kubernetes-client-windows-amd64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 104282485 10月 31 17:23 kubernetes-node-linux-amd64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 422609440 10月 31 17:23 kubernetes-server-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>
<p>解压kubernetes-server-linux-amd64.tar.gz<br>并将解压的目录改名kubernetes</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 kubernetes]# cd kubernetes/</span><br><span class="line">[root@vmlinux4 kubernetes]# ll</span><br><span class="line">总用量 238020</span><br><span class="line">drwxr-xr-x. 2 root root      4096 10月  6 2018 addons</span><br><span class="line">drwxr-xr-x. 3 root root      4096 9月  22 2018 client</span><br><span class="line">drwxr-xr-x. 2 root root      4096 11月  1 17:30 config</span><br><span class="line">-rw-r--r--. 1 root root  28023710 10月  6 2018 kubernetes-src.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root   6102560 10月  6 2018 LICENSES</span><br><span class="line">drwxr-xr-x. 3 root root      4096 10月  6 2018 server</span><br></pre></td></tr></table></figure>
<p>将server&#x2F;bin中的可执行文件复制到&#x2F;usr&#x2F;bin中</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 bin]# cd server/bin</span><br><span class="line">[root@vmlinux4 bin]# cp kube-apiserver kube-controller-manager kubectl kubelet kube-proxy /usr/bin</span><br></pre></td></tr></table></figure>
<h4 id="（1）创建kube-apiserver的配置文件"><a href="#（1）创建kube-apiserver的配置文件" class="headerlink" title="（1）创建kube-apiserver的配置文件"></a>（1）创建kube-apiserver的配置文件</h4><p>创建一个存放配置文件的目录，创建配置文件apiserver<br>具体配置如下</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# ll</span><br><span class="line">total 28</span><br><span class="line">-rw-r--r--. 1 root root  313 Nov 11 16:55 apiserver</span><br><span class="line">-rw-r--r--. 1 root root  172 Nov  6 11:34 controller-manager</span><br><span class="line">-rw-r--r--. 1 root root  355 Nov 11 16:55 kubelet</span><br><span class="line">-rw-r--r--. 1 root root  234 Oct 31 17:48 kubelet.kubeconfig</span><br><span class="line">-rw-r--r--. 1 root root  112 Nov  8 12:00 kube-proxy</span><br><span class="line">-rw-r--r--. 1 root root   90 Nov  4 09:05 scheduler</span><br><span class="line">-rw-r--r--. 1 root root 1679 Nov  6 11:09 serviceaccount.key</span><br><span class="line">[root@vmlinux4 config]# pwd</span><br><span class="line">/sga/kubernetes/kubernetes/config</span><br><span class="line">[root@vmlinux4 config]# cat apiserver</span><br><span class="line">KUBE_API_ARGS=&quot;--service-account-key-file=/sga/kubernetes/kubernetes/config/serviceaccount.key --logtostderr=true --v=4 --etcd-servers=http://192.168.0.104:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --advertise-address=192.168.0.104 --allow-privileged=true --service-cluster-ip-range=192.0.0.0/24&quot;</span><br></pre></td></tr></table></figure>

<h4 id="（2）创建kube-apiserver服务"><a href="#（2）创建kube-apiserver服务" class="headerlink" title="（2）创建kube-apiserver服务"></a>（2）创建kube-apiserver服务</h4><p>创建kube-apiserver服务的启动文件</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 kubernetes]# cat /lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line">After=etcd.service</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/sga/kubernetes/kubernetes/config/apiserver</span><br><span class="line">ExecStart=/usr/bin/kube-apiserver $KUBE_API_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<h4 id="（3）启动kube-apiserver服务"><a href="#（3）启动kube-apiserver服务" class="headerlink" title="（3）启动kube-apiserver服务"></a>（3）启动kube-apiserver服务</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# service kube-apiserver start</span><br><span class="line">Redirecting to /bin/systemctl start kube-apiserver.service</span><br><span class="line">[root@vmlinux4 config]# service kube-apiserver status</span><br><span class="line">Redirecting to /bin/systemctl status kube-apiserver.service</span><br><span class="line">● kube-apiserver.service - Kubernetes API Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kube-apiserver.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Mon 2019-11-11 16:57:02 CST; 17h ago</span><br><span class="line">     Docs: https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"> Main PID: 88747 (kube-apiserver)</span><br><span class="line">    Tasks: 12</span><br><span class="line">   Memory: 237.0M</span><br><span class="line">   CGroup: /system.slice/kube-apiserver.service</span><br><span class="line">           └─88747 /usr/bin/kube-apiserver --service-account-key-file=/sga/kubernetes/kubernetes/config/serviceaccount.key --logtostderr=true --v=4 --etcd-servers=http...</span><br><span class="line"></span><br><span class="line">Nov 12 10:01:04 vmlinux4 kube-apiserver[88747]: I1112 10:01:04.222112   88747 wrap.go:42] PUT /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.storage.k8s...:1]:57015]</span><br><span class="line">Nov 12 10:01:04 vmlinux4 kube-apiserver[88747]: I1112 10:01:04.491035   88747 wrap.go:42] GET /api/v1/namespaces/kube-system/endpoints/kube-scheduler?timeout...104:43405]</span><br><span class="line">Nov 12 10:01:04 vmlinux4 kube-apiserver[88747]: I1112 10:01:04.501490   88747 wrap.go:42] PUT /api/v1/namespaces/kube-system/endpoints/kube-scheduler?timeout...104:43405]</span><br><span class="line">Nov 12 10:01:05 vmlinux4 kube-apiserver[88747]: I1112 10:01:05.199210   88747 wrap.go:42] GET /apis/scheduling.k8s.io/v1beta1/priorityclasses?resourceVersion...:1]:57015]</span><br><span class="line">Nov 12 10:01:05 vmlinux4 kube-apiserver[88747]: I1112 10:01:05.199583   88747 reflector.go:357] k8s.io/kubernetes/pkg/client/informers/informers_generated/in...s received</span><br><span class="line">Nov 12 10:01:05 vmlinux4 kube-apiserver[88747]: I1112 10:01:05.200498   88747 get.go:245] Starting watch for /apis/scheduling.k8s.io/v1beta1/priorityclasses,...eout=9m12s</span><br><span class="line">Nov 12 10:01:05 vmlinux4 kube-apiserver[88747]: I1112 10:01:05.959651   88747 wrap.go:42] GET /api/v1/namespaces/kube-system/endpoints/kube-controller-manage...104:30938]</span><br><span class="line">Nov 12 10:01:05 vmlinux4 kube-apiserver[88747]: I1112 10:01:05.967240   88747 wrap.go:42] PUT /api/v1/namespaces/kube-system/endpoints/kube-controller-manage...104:30938]</span><br><span class="line">Nov 12 10:01:06 vmlinux4 kube-apiserver[88747]: I1112 10:01:06.513381   88747 wrap.go:42] GET /api/v1/namespaces/kube-system/endpoints/kube-scheduler?timeout...104:43405]</span><br><span class="line">Nov 12 10:01:06 vmlinux4 kube-apiserver[88747]: I1112 10:01:06.520963   88747 wrap.go:42] PUT /api/v1/namespaces/kube-system/endpoints/kube-scheduler?timeout...104:43405]</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full.</span><br></pre></td></tr></table></figure>

<h3 id="4-安装kube-controller-manager"><a href="#4-安装kube-controller-manager" class="headerlink" title="4.安装kube-controller-manager"></a>4.安装kube-controller-manager</h3><p>此服务是kubernetes-server-linux-amd64.tar.gz中的组件，在服务端安装</p>
<h4 id="（1）创建controller-manager配置文件"><a href="#（1）创建controller-manager配置文件" class="headerlink" title="（1）创建controller-manager配置文件"></a>（1）创建controller-manager配置文件</h4><p>在config目录中创建controller-manager的配置文件controller-manager</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# pwd</span><br><span class="line">/sga/kubernetes/kubernetes/config</span><br><span class="line">[root@vmlinux4 config]# ll</span><br><span class="line">总用量 12</span><br><span class="line">-rw-r--r--. 1 root root 234 11月  1 17:07 apiserver</span><br><span class="line">-rw-r--r--. 1 root root  84 11月  1 17:30 controller-manager</span><br><span class="line">[root@vmlinux4 config]# cat controller-manager</span><br><span class="line">KUBE_CONTROLLER_MANAGER_ARGS=&quot;--logtostderr=true --v=4 --master=192.168.0.104:8080&quot;</span><br></pre></td></tr></table></figure>
<h4 id="（2）创建-controller-manager服务"><a href="#（2）创建-controller-manager服务" class="headerlink" title="（2）创建 controller-manager服务"></a>（2）创建 controller-manager服务</h4><p>创建controller-manager的服务启动文件</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# cat /lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/sga/kubernetes/kubernetes/config/controller-manager</span><br><span class="line">ExecStart=/usr/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<h4 id="（3）启动kube-controller-manager服务"><a href="#（3）启动kube-controller-manager服务" class="headerlink" title="（3）启动kube-controller-manager服务"></a>（3）启动kube-controller-manager服务</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# service kube-apiserver start</span><br><span class="line">Redirecting to /bin/systemctl start kube-apiserver.service</span><br><span class="line">[root@vmlinux4 config]# service kube-apiserver status</span><br><span class="line">Redirecting to /bin/systemctl status kube-apiserver.service</span><br><span class="line">● kube-apiserver.service - Kubernetes API Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kube-apiserver.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 五 2019-11-01 17:07:26 CST; 5s ago</span><br><span class="line">     Docs: https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"> Main PID: 6707 (kube-apiserver)</span><br><span class="line">    Tasks: 10</span><br><span class="line">   Memory: 269.6M</span><br><span class="line">   CGroup: /system.slice/kube-apiserver.service</span><br><span class="line">           └─6707 /usr/bin/kube-apiserver --logtostderr=true --v=4 --etcd-servers=http://192.168.0.104:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --ad...</span><br><span class="line"></span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.293559    6707 wrap.go:42] PUT /apis/apiregistration.k8s.io/v1/apiservices/v1.authentication...1]:39204]</span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.294208    6707 wrap.go:42] PUT /apis/apiregistration.k8s.io/v1/apiservices/v2beta2.autoscali...1]:39204]</span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.295948    6707 wrap.go:42] PUT /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.apiextens...1]:39204]</span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.297403    6707 wrap.go:42] PUT /apis/apiregistration.k8s.io/v1/apiservices/v1beta1.policy/st...1]:39204]</span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.986544    6707 wrap.go:42] GET /api/v1/namespaces/kube-system: (3.772385ms) 200 [kube-apiser...1]:39204]</span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.986614    6707 wrap.go:42] GET /apis/scheduling.k8s.io/v1beta1/priorityclasses/system-node-c...1]:39204]</span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.992903    6707 wrap.go:42] GET /apis/scheduling.k8s.io/v1beta1/priorityclasses/system-cluste...1]:39204]</span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.993907    6707 wrap.go:42] GET /api/v1/namespaces/kube-system/configmaps/extension-apiserver...1]:39204]</span><br><span class="line">11月 01 17:07:27 vmlinux4 kube-apiserver[6707]: I1101 17:07:27.996664    6707 storage_scheduling.go:100] all system priority classes are created successful...dy exist.</span><br><span class="line">11月 01 17:07:28 vmlinux4 kube-apiserver[6707]: I1101 17:07:28.000849    6707 wrap.go:42] PUT /api/v1/namespaces/kube-system/configmaps/extension-apiserver...1]:39204]</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full.</span><br></pre></td></tr></table></figure>

<h3 id="5-安装kube-scheduler"><a href="#5-安装kube-scheduler" class="headerlink" title="5.安装kube-scheduler"></a>5.安装kube-scheduler</h3><p>kube-scheduler在服务端安装</p>
<h4 id="（1）创建kube-controller-manager配置文件"><a href="#（1）创建kube-controller-manager配置文件" class="headerlink" title="（1）创建kube-controller-manager配置文件"></a>（1）创建kube-controller-manager配置文件</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# cat scheduler</span><br><span class="line">KUBE_SCHEDULER_ARGS=&quot;--logtostderr=true --v=4 --master=192.168.0.104:8080 --leader-elect&quot;</span><br></pre></td></tr></table></figure>

<h4 id="（2）创建kube-scheduler服务文件"><a href="#（2）创建kube-scheduler服务文件" class="headerlink" title="（2）创建kube-scheduler服务文件"></a>（2）创建kube-scheduler服务文件</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# cat /lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler Plugin</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/sga/kubernetes/kubernetes/config/scheduler</span><br><span class="line">ExecStart=/usr/bin/kube-scheduler $KUBE_SCHEDULER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<h4 id="（3）启动kube-scheduler服务"><a href="#（3）启动kube-scheduler服务" class="headerlink" title="（3）启动kube-scheduler服务"></a>（3）启动kube-scheduler服务</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# service kube-scheduler status</span><br><span class="line">Redirecting to /bin/systemctl status kube-scheduler.service</span><br><span class="line">● kube-scheduler.service - Kubernetes Scheduler Plugin</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kube-scheduler.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 一 2019-11-11 16:56:53 CST; 6 days ago</span><br><span class="line">     Docs: https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"> Main PID: 88984 (kube-scheduler)</span><br><span class="line">    Tasks: 11</span><br><span class="line">   Memory: 20.0M</span><br><span class="line">   CGroup: /system.slice/kube-scheduler.service</span><br><span class="line">           └─88984 /usr/bin/kube-scheduler --logtostderr=true --v=4 --master=192.168.0.104:8080 --leader-elect</span><br><span class="line"></span><br><span class="line">11月 18 08:37:04 vmlinux4 kube-scheduler[88984]: I1118 08:37:04.461613   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">11月 18 08:37:06 vmlinux4 kube-scheduler[88984]: I1118 08:37:06.474800   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">11月 18 08:37:08 vmlinux4 kube-scheduler[88984]: I1118 08:37:08.490991   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">11月 18 08:37:08 vmlinux4 kube-scheduler[88984]: I1118 08:37:08.941170   88984 reflector.go:357] k8s.io/client-go/informers/factory.go:131: Watch close - *... received</span><br><span class="line">11月 18 08:37:10 vmlinux4 kube-scheduler[88984]: I1118 08:37:10.512228   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">11月 18 08:37:12 vmlinux4 kube-scheduler[88984]: I1118 08:37:12.526609   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">11月 18 08:37:14 vmlinux4 kube-scheduler[88984]: I1118 08:37:14.541069   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">11月 18 08:37:16 vmlinux4 kube-scheduler[88984]: I1118 08:37:16.559766   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">11月 18 08:37:18 vmlinux4 kube-scheduler[88984]: I1118 08:37:18.573130   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">11月 18 08:37:20 vmlinux4 kube-scheduler[88984]: I1118 08:37:20.588158   88984 leaderelection.go:227] successfully renewed lease kube-system/kube-scheduler</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full.</span><br></pre></td></tr></table></figure>

<h3 id="6-安装kubelet"><a href="#6-安装kubelet" class="headerlink" title="6.安装kubelet"></a>6.安装kubelet</h3><p>所有服务器都安装kubelet，在所有的服务器上创建如下三个配置文件</p>
<h4 id="（1）创建kubeconfig配置文件"><a href="#（1）创建kubeconfig配置文件" class="headerlink" title="（1）创建kubeconfig配置文件"></a>（1）创建kubeconfig配置文件</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 ~]# vim /sga/kubernetes/kubernetes/config/kubelet.kubeconfig</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Config</span><br><span class="line">clusters:</span><br><span class="line">  - cluster:</span><br><span class="line">      server: http://192.168.0.104:8080                ###Master的IP，即自身IP</span><br><span class="line">    name: local</span><br><span class="line">contexts:</span><br><span class="line">  - context:</span><br><span class="line">      cluster: local</span><br><span class="line">    name: local</span><br><span class="line">current-context: local    </span><br></pre></td></tr></table></figure>

<h4 id="（2）创建kubelet配置文件"><a href="#（2）创建kubelet配置文件" class="headerlink" title="（2）创建kubelet配置文件"></a>（2）创建kubelet配置文件</h4><p>创建kubelet配置文件</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# cat kubelet</span><br><span class="line">KUBE_KUBELET_ARGS=&quot;--feature-gates=AttachVolumeLimit=false --cluster_dns=10.10.10.10 --cluster_domain=cluster.local --logtostderr=true --v=4 --address=192.168.0.104 --port=10250 --hostname-override=192.168.0.104 --kubeconfig=/sga/kubernetes/kubernetes/config/kubelet.kubeconfig --allow-privileged=true --cluster-domain=cluster.local --fail-swap-on=false&quot;</span><br></pre></td></tr></table></figure>
<h4 id="（3）创建kubelet服务文件"><a href="#（3）创建kubelet服务文件" class="headerlink" title="（3）创建kubelet服务文件"></a>（3）创建kubelet服务文件</h4><p>创建kubelet启动的服务文件</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# cat /lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/sga/kubernetes/kubernetes/config/kubelet</span><br><span class="line">ExecStart=/usr/bin/kubelet $KUBE_KUBELET_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">KillMode=process</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<h4 id="（4）启动服务，并设置开机启动"><a href="#（4）启动服务，并设置开机启动" class="headerlink" title="（4）启动服务，并设置开机启动"></a>（4）启动服务，并设置开机启动</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@server1 ~]# swapoff -a ###启动之前要先关闭swap</span><br><span class="line">[root@server1 ~]# systemctl enable kubelet</span><br><span class="line">[root@server1 ~]# systemctl start kubelet</span><br></pre></td></tr></table></figure>


<h3 id="7-安装kube-proxy"><a href="#7-安装kube-proxy" class="headerlink" title="7.安装kube-proxy"></a>7.安装kube-proxy</h3><p>所有服务器都安装kube-proxy，创建如下两个配置文件</p>
<h4 id="（1）创建proxy配置文件"><a href="#（1）创建proxy配置文件" class="headerlink" title="（1）创建proxy配置文件"></a>（1）创建proxy配置文件</h4><p>在config目录创建配置文件</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# cat kube-proxy</span><br><span class="line">KUBE_PROXY_ARGS=&quot;--logtostderr=true --v=4 --hostname-override=192.168.0.104 --master=http://192.168.0.104:8080&quot;</span><br></pre></td></tr></table></figure>
<h4 id="（2）创建proxy服务文件"><a href="#（2）创建proxy服务文件" class="headerlink" title="（2）创建proxy服务文件"></a>（2）创建proxy服务文件</h4><p>创建proxy服务的启动文件</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# cat /lib/systemd/system/kube-proxy.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/sga/kubernetes/kubernetes/config/kube-proxy</span><br><span class="line">ExecStart=/usr/bin/kube-proxy $KUBE_PROXY_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<h4 id="（3）启动服务-1"><a href="#（3）启动服务-1" class="headerlink" title="（3）启动服务"></a>（3）启动服务</h4><h3 id="8．安装flannel"><a href="#8．安装flannel" class="headerlink" title="8．安装flannel"></a>8．安装flannel</h3><p>所有服务器都安装</p>
<h4 id="（1）创建配置文件"><a href="#（1）创建配置文件" class="headerlink" title="（1）创建配置文件"></a>（1）创建配置文件</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# pwd</span><br><span class="line">/sga/kubernetes/flannel/config</span><br><span class="line">[root@vmlinux4 config]# cat flanneld.conf</span><br><span class="line"># Flanneld configuration options</span><br><span class="line"># etcd url location.  Point this to the server where etcd runs，自身IP</span><br><span class="line">FLANNEL_ETCD=&quot;http://192.168.0.104:2379&quot;</span><br><span class="line"></span><br><span class="line"># etcd config key.  This is the configuration key that flannel queries</span><br><span class="line"># For address range assignment，etcd-key的目录</span><br><span class="line">FLANNEL_ETCD_KEY=&quot;/etc/kubernetes/network&quot;</span><br><span class="line"></span><br><span class="line"># Any additional options that you want to pass，根据自己的网卡名填写</span><br><span class="line">FLANNEL_OPTIONS=&quot;--iface=ens33&quot;</span><br></pre></td></tr></table></figure>

<h4 id="（2）创建服务文件"><a href="#（2）创建服务文件" class="headerlink" title="（2）创建服务文件"></a>（2）创建服务文件</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# cat /lib/systemd/system/flanneld.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Flanneld overlay address etcd agent</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">After=etcd.service</span><br><span class="line">Before=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=/sga/kubernetes/flannel/config/flanneld.conf</span><br><span class="line">ExecStart=/usr/bin/flanneld -etcd-endpoints=$&#123;FLANNEL_ETCD&#125; -etcd-prefix=$&#123;FLANNEL_ETCD_KEY&#125; $FLANNEL_OPTIONS</span><br><span class="line">ExecStartPost=/usr/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">RequiredBy=docker.service</span><br></pre></td></tr></table></figure>
<h4 id="（3）配置etcd"><a href="#（3）配置etcd" class="headerlink" title="（3）配置etcd"></a>（3）配置etcd</h4><p>此处对应配置文件中的FLANNEL_ETCD_KEY&#x3D;”&#x2F;etc&#x2F;kubernetes&#x2F;network”</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# etcdctl set /etc/kubernetes/network/config &#x27;&#123;&quot;Network&quot;: &quot;172.20.0.0/16&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<h4 id="（4）配置docker"><a href="#（4）配置docker" class="headerlink" title="（4）配置docker"></a>（4）配置docker</h4><p>上文中提到的docker的调整<br>修改docker.service在[Service]添加如下参数，是为了由flannel统一接管docker的服务请求，flannel运行生成一个配置文件，docker调用这个配置文件使docker的VIP与flannel的VIP处于同一网段，如此才能由flannel来统一管理</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# vim /lib/systemd/system/docker.service</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line"># the default is not to use systemd for cgroups because the delegate issues still</span><br><span class="line"># exists and systemd currently does not support the cgroup feature set required</span><br><span class="line">EnvironmentFile=-/sga/kubernetes/flannel/config/flanneld</span><br><span class="line">EnvironmentFile=-/run/flannel/subnet.env #flannel生成的配置文件</span><br><span class="line">ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --bip=$&#123;FLANNEL_SUBNET&#125;</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">TimeoutSec=0</span><br><span class="line">RestartSec=2</span><br><span class="line">Restart=always</span><br></pre></td></tr></table></figure>
<p>执行命令刷新服务</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux5 config]# systemctl daemon-reload</span><br><span class="line">[root@vmlinux5 config]# sercice flannel restart</span><br><span class="line">[root@vmlinux5 config]# sercice docker restart</span><br></pre></td></tr></table></figure>
<h4 id="（5）启动验证服务"><a href="#（5）启动验证服务" class="headerlink" title="（5）启动验证服务"></a>（5）启动验证服务</h4><p>查看docker与flannel的ip处于同一网段即可</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 config]# ip addr</span><br><span class="line">7: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default</span><br><span class="line">    link/ether 02:42:a8:a9:f1:83 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.20.64.1/24 brd 172.20.64.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">9: flannel0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1472 qdisc pfifo_fast state UNKNOWN group default qlen 500</span><br><span class="line">    link/none</span><br><span class="line">    inet 172.20.64.0/32 scope global flannel0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::5ddd:d4ba:8977:1fad/64 scope link flags 800</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<h3 id="9．准备docker-flink镜像"><a href="#9．准备docker-flink镜像" class="headerlink" title="9．准备docker-flink镜像"></a>9．准备docker-flink镜像</h3><h4 id="（1）下载镜像"><a href="#（1）下载镜像" class="headerlink" title="（1）下载镜像"></a>（1）下载镜像</h4><p>由于是离线部署flink，所以需要提前下载flink-docker镜像，我对于docker镜像还不是很了解，不知道能不能使用flink的安装包来制作docker镜像，所以只能联网下载，以后再做研究<br>将服务器联网</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 conf]# docker pull flink:1.7.2</span><br><span class="line">1.7.2: Pulling from library/flink</span><br><span class="line">9cc2ad81d40d: Pull complete</span><br><span class="line">e6cb98e32a52: Pull complete</span><br><span class="line">ae1b8d879bad: Pull complete</span><br><span class="line">2383fa4462e7: Pull complete</span><br><span class="line">7ac3ce9f2067: Pull complete</span><br><span class="line">ce9a16d8ddcb: Pull complete</span><br><span class="line">d0078391b205: Pull complete</span><br><span class="line">cb7d61aa945e: Pull complete</span><br><span class="line">5dcb8e0f7236: Pull complete</span><br><span class="line">f3f880699fcf: Pull complete</span><br><span class="line">ffa37d915f80: Pull complete</span><br><span class="line">0b51594f6132: Pull complete</span><br><span class="line">Digest: sha256:02847d6cc09bfe5fa6c1f347e499984af44537f68188578d6173636618ae7a39</span><br><span class="line">Status: Downloaded newer image for flink:1.7.2</span><br></pre></td></tr></table></figure>

<p>下载pause:3.1镜像</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# docker pull registry.cn-beijing.aliyuncs.com/zhoujun/pause:3.1</span><br></pre></td></tr></table></figure>
<p>将下载的pause镜像改名</p>
<h4 id="（2）查看镜像"><a href="#（2）查看镜像" class="headerlink" title="（2）查看镜像"></a>（2）查看镜像</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# docker image ls</span><br><span class="line">REPOSITORY		TAG		IMAGE ID			CREATED			SIZE</span><br><span class="line">fink			 	1.7		cb399bafceb4		2 months ago		534MB</span><br><span class="line">flink				1.7.2	cb399bafceb4		2 months ago		534MB</span><br><span class="line">k8s.gcr.io/pause	3.1		da86e6ba6ca1		22 months ago	742kB</span><br></pre></td></tr></table></figure>

<h4 id="（3）镜像打包"><a href="#（3）镜像打包" class="headerlink" title="（3）镜像打包"></a>（3）镜像打包</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# docker save fink:1.7 &gt; flink.tar</span><br><span class="line">[root@vmlinux4 pods]# docker save k8s.gcr.io/pause:3.1 &gt; pause3.1.tar</span><br></pre></td></tr></table></figure>
<p>将镜像传送到所有服务器上</p>
<h4 id="（4）镜像导入"><a href="#（4）镜像导入" class="headerlink" title="（4）镜像导入"></a>（4）镜像导入</h4><p>在其余服务器上导入相应的包</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# docker load &lt; flink.tar</span><br><span class="line">[root@vmlinux4 pods]# docker load &lt; pause3.1.tar</span><br></pre></td></tr></table></figure>
<p>至此，k8s运行flink集群所需的镜像包下载完成</p>
<h3 id="10．flink-on-kubernetes配置"><a href="#10．flink-on-kubernetes配置" class="headerlink" title="10．flink on kubernetes配置"></a>10．flink on kubernetes配置</h3><p>经过前面那些步骤的安装配置以后，才进入到主题：flink on kubernetes的配置</p>
<h4 id="（1）创建kubernetes服务文件"><a href="#（1）创建kubernetes服务文件" class="headerlink" title="（1）创建kubernetes服务文件"></a>（1）创建kubernetes服务文件</h4><p>flink on kubernetes有两种运行模式，一种会话集群，一种工作集群，这里采用会话集群的模式进行部署，共三个文件，分别如下</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# cat jobmanager-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">    name: flink-jobmanager</span><br><span class="line">spec:</span><br><span class="line">    clusterIP: 192.0.0.200</span><br><span class="line">    ports:</span><br><span class="line">    - name: rpc</span><br><span class="line">      port: 6123</span><br><span class="line">    - name: blob</span><br><span class="line">      port: 6124</span><br><span class="line">    - name: query</span><br><span class="line">      port: 6125</span><br><span class="line">    - name: ui</span><br><span class="line">      port: 8081</span><br><span class="line">    selector:</span><br><span class="line">        app: flink</span><br><span class="line">        component: jobmanager</span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# cat jobmanager-deployment.yaml</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">    name: flink-jobmanager</span><br><span class="line">spec:</span><br><span class="line">    replicas: 1</span><br><span class="line">    template:</span><br><span class="line">        metadata:</span><br><span class="line">            labels:</span><br><span class="line">                app: flink</span><br><span class="line">                component: jobmanager</span><br><span class="line">        spec:</span><br><span class="line">            containers:</span><br><span class="line">            - name: jobmanager</span><br><span class="line">              image: flink:1.7</span><br><span class="line">              args:</span><br><span class="line">              - jobmanager</span><br><span class="line">              ports:</span><br><span class="line">              - containerPort: 6123</span><br><span class="line">                name: rpc</span><br><span class="line">              - containerPort: 6124</span><br><span class="line">                name: blob</span><br><span class="line">              - containerPort: 6125</span><br><span class="line">                name: query</span><br><span class="line">              - containerPort: 8081</span><br><span class="line">                name: ui</span><br><span class="line">              env:</span><br><span class="line">              - name: JOB_MANAGER_RPC_ADDRESS</span><br><span class="line">                value: 192.0.0.200</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# cat taskmanager-deployment.yaml</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">    name: flink-taskmanager</span><br><span class="line">spec:</span><br><span class="line">    replicas: 3</span><br><span class="line">    template:</span><br><span class="line">        metadata:</span><br><span class="line">            labels:</span><br><span class="line">                app: flink</span><br><span class="line">                component: taskmanager</span><br><span class="line">        spec:</span><br><span class="line">            containers:</span><br><span class="line">            - name: taskmanager</span><br><span class="line">              image: flink:1.7</span><br><span class="line">              args:</span><br><span class="line">              - taskmanager</span><br><span class="line">              ports:</span><br><span class="line">              - containerPort: 6121</span><br><span class="line">                name: data</span><br><span class="line">              - containerPort: 6122</span><br><span class="line">                name: rpc</span><br><span class="line">              - containerPort: 6125</span><br><span class="line">                name: query</span><br><span class="line">              env:</span><br><span class="line">              - name: JOB_MANAGER_RPC_ADDRESS</span><br><span class="line">                value: 192.0.0.200</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="（2）启动flink会话集群"><a href="#（2）启动flink会话集群" class="headerlink" title="（2）启动flink会话集群"></a>（2）启动flink会话集群</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# kubectl create -f jobmanager-service.yaml</span><br><span class="line">service/flink-jobmanager create</span><br><span class="line">[root@vmlinux4 pods]# kubectl create -f jobmanager-deployment.yaml</span><br><span class="line">deployment.extensions/flink-jobmanager create</span><br><span class="line">[root@vmlinux4 pods]# kubectl create -f taskmanager-deployment.yaml</span><br><span class="line">deployment.extensions/flink-taskmanager create</span><br></pre></td></tr></table></figure>
<p>集群启动完成<br>查看启动情况</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# kubectl get pod -o wide</span><br><span class="line">NAME                                READY   STATUS    RESTARTS   AGE    IP            NODE            NOMINATED NODE</span><br><span class="line">flink-jobmanager-84f5464b7c-h74gt   1/1     Running   0          130m   172.20.87.2   192.168.0.106   &lt;none&gt;</span><br><span class="line">flink-taskmanager-8d856fc49-b9sx9   1/1     Running   0          130m   172.20.69.2   192.168.0.105   &lt;none&gt;</span><br><span class="line">flink-taskmanager-8d856fc49-vpz99   1/1     Running   0          130m   172.20.87.3   192.168.0.106   &lt;none&gt;</span><br><span class="line">flink-taskmanager-8d856fc49-xfdr2   1/1     Running   0          130m   172.20.64.2   192.168.0.104   &lt;none&gt;</span><br></pre></td></tr></table></figure>
<h4 id="（3）启动service的对外服务"><a href="#（3）启动service的对外服务" class="headerlink" title="（3）启动service的对外服务"></a>（3）启动service的对外服务</h4><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 pods]# kubectl proxy --address=’192.168.0.104’ -p=8001 --accept-hosts=’^*$’</span><br><span class="line">Staring to server on 192.168.0.104:8001</span><br></pre></td></tr></table></figure>
<h4 id="（4）访问flink"><a href="#（4）访问flink" class="headerlink" title="（4）访问flink"></a>（4）访问flink</h4><p>在浏览器输入地址<br><a target="_blank" rel="noopener" href="http://192.168.0.104:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy">http://192.168.0.104:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy</a><br>访问flink<br><img src="/myblog/myblog/2023/03/02/7-%E5%A4%A7%E6%95%B0%E6%8D%AE/7-flink/k8s%E5%AE%89%E8%A3%85flink/img.png" alt="img.png"></p>
<h2 id="四、报错处理"><a href="#四、报错处理" class="headerlink" title="四、报错处理"></a>四、报错处理</h2><p>以下是安装过程中遇到的报错</p>
<h3 id="1-启动etcd报错"><a href="#1-启动etcd报错" class="headerlink" title="1.启动etcd报错"></a>1.启动etcd报错</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux1 bin]# kube-apiserver $KUBE_API_ARGS</span><br><span class="line">[root@vmlinux1 bin]# echo $KUBE_API_ARGS</span><br><span class="line">–storage-backend=etcd3 --etcd-servers=http://192.168.0.101:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --service-cluster-ip-range=169.169.0.0/16 --service-node-port-range=1-65535 --admission-control=NamespaceLifecycle,LimitRanger,ResourceQuota --logtostderr=false --log-dir=/var/log/kubernets/log --v=2</span><br><span class="line"></span><br><span class="line">E1024 16:42:22.290363 93923 repair.go:171] the cluster IP 10.0.0.1 for service kubernetes/default is not within the service CIDR 169.169.0.0/16; please recreate</span><br><span class="line">E1024 16:42:22.290861 93923 repair.go:188] the cluster IP 10.0.0.1 may have leaked: flagging for later clean up</span><br><span class="line">E1024 16:42:22.293248 93923 repair.go:195] the cluster IP 10.0.0.1 may have leaked, but can not be allocated: provided IP is not in the valid range. The range of valid IPs is 169.169.0.0/16</span><br><span class="line">E1024 16:42:22.320465 93923 repair.go:171] the cluster IP 10.0.0.1 for service kubernetes/default is not within the service CIDR 169.169.0.0/16; please recreate</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>启动etcd报错<br>rafthttp: failed to find member as2das3eadasd in cluster 2323432kjh4bjwhbd<br>注意:节点删除后，集群中的成员信息会更新，新节点加入集群是作为一个全新的节点加入，如果data-dir有数据，etcd启动时会读取己经存在的数据，启动时仍然用的老member ID,也会造成，集群不无法加入，所以一定要清空新节点的data-dir</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">etcdctl mk /atomic.io/network/config “&#123; “Network”: “172.17.0.0/16”, “SubnetLen”: 24, “Backend”: &#123; “Type”: “vxlan” &#125; &#125;” &#123; “Network”: “172.17.0.0/16”, “SubnetLen”: 24,“Backend”: &#123; “Type”: “vxlan” &#125; &#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-Etcd启动若出现E-rafthttp-request-sent-was-ignored-cluster-ID-mismatch-peer…-local-x3D-…"><a href="#2-Etcd启动若出现E-rafthttp-request-sent-was-ignored-cluster-ID-mismatch-peer…-local-x3D-…" class="headerlink" title="2.Etcd启动若出现E | rafthttp: request sent was ignored (cluster ID mismatch: peer… local&#x3D;…)"></a>2.Etcd启动若出现E | rafthttp: request sent was ignored (cluster ID mismatch: peer… local&#x3D;…)</h3><p>删除etcd各个服务器根目录下的my-etcd-1.etcd目录重新启动</p>
<h3 id="3-Unable-to-configure-the-docker-daemon-with-file-x2F-etc-x2F-docker-x2F-daemon-json"><a href="#3-Unable-to-configure-the-docker-daemon-with-file-x2F-etc-x2F-docker-x2F-daemon-json" class="headerlink" title="3.Unable to configure the docker daemon with file &#x2F;etc&#x2F;docker&#x2F;daemon.json"></a>3.Unable to configure the docker daemon with file &#x2F;etc&#x2F;docker&#x2F;daemon.json</h3><p>删除文件&#x2F;etc&#x2F;docker&#x2F;daemon.json</p>
<h3 id="4-Kubectl-get-pods时报错No-resources-found"><a href="#4-Kubectl-get-pods时报错No-resources-found" class="headerlink" title="4.Kubectl get pods时报错No resources found"></a>4.Kubectl get pods时报错No resources found</h3><p>生成秘钥到配置文件目录<br>openssl genrsa -out &#x2F;…<br>修改kube-apiserver配置文件<br>添加–service-account-key-file&#x3D;&#x2F;…&#x2F;serviceaccount.key<br>修改kube-controller-manager配置文件<br>添加–service-account-private-key-file&#x3D;&#x2F;…&#x2F;serviceaccount.key<br>重启etcd,docker,flanneld,kube-apiserver,kube-controller-manager,kube-scheduler,kube-proxy,kubelet</p>
<h3 id="5-Warning-MissingClusterDNS"><a href="#5-Warning-MissingClusterDNS" class="headerlink" title="5.Warning MissingClusterDNS"></a>5.Warning MissingClusterDNS</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@vmlinux4 ~]# kubectl get pods -o wide</span><br><span class="line">NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE</span><br><span class="line">flink-jobmanager-5f6879585d-tswht 0/1 ContainerCreating 0 20h 192.168.0.105</span><br><span class="line">flink-taskmanager-69d55dd9bb-2hrgd 0/1 ContainerCreating 0 20h 192.168.0.105</span><br><span class="line">flink-taskmanager-69d55dd9bb-dp6nx 0/1 ContainerCreating 0 20h 192.168.0.106</span><br><span class="line">flink-taskmanager-69d55dd9bb-vdssm 0/1 ContainerCreating 0 20h 192.168.0.104</span><br><span class="line"></span><br><span class="line">[root@vmlinux4 ~]# kubectl describe pod flink-jobmanager-5f6879585d-tswht</span><br><span class="line">Warning MissingClusterDNS 4m11s (x5769 over 20h) kubelet, 192.168.0.105 pod: “flink-jobmanager-5f6879585d-tswht_default(886b9cbc-0046-11ea-8468-000c2952c691)”. kubelet does not have ClusterDNS IP configured and cannot create Pod using “ClusterFirst” policy. Falling back to “Default” policy.</span><br></pre></td></tr></table></figure>
<p>kubelet添加参数–cluster_dns&#x3D;10.10.10.10 –cluster_domain&#x3D;cluster.local</p>
<h3 id="6-Kubernetes从k8s-gcr-io拉取镜像失败问题"><a href="#6-Kubernetes从k8s-gcr-io拉取镜像失败问题" class="headerlink" title="6.Kubernetes从k8s.gcr.io拉取镜像失败问题"></a>6.Kubernetes从k8s.gcr.io拉取镜像失败问题</h3><p>kubectl describe pod flink-jobmanager<br>mage pull failed for gcr.io&#x2F;google_containers&#x2F;pause:2.0<br>Kubernetes从k8s.gcr.io拉取镜像失败问题，pause-amd64:3.1、pause:3.1、kube相关的基础镜像<br>在国内，通过Docker的pull和push命令访问hub.docker时，网络十分慢，而且会出现各种各样的网络连接问题。而且像部分k8s必须的镜像无法下载下来。</p>
<p>解决办法，可从国内的镜像仓库下载下来，通过docker tar指令修改成相应的版本，示例如下：</p>
<p>docker pull registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;pause-amd64:3.1<br>docker pull registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;kube-proxy-amd64:v1.11.3<br>docker pull registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;kube-scheduler-amd64:v1.11.3<br>docker pull registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;coredns:1.1.3<br>docker pull registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;pause:3.1<br>docker pull registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;kube-controller-manager-amd64:v1.11.3<br>docker pull registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;kube-apiserver-amd64:v1.11.3<br>docker pull registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;etcd-amd64:3.2.18<br>然后修改版本：</p>
<p>docker tag registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;kube-proxy-amd64:v1.11.3 k8s.gcr.io&#x2F;kube-proxy-amd64:v1.11.3<br>docker tag registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;kube-scheduler-amd64:v1.11.3 k8s.gcr.io&#x2F;kube-scheduler-amd64:v1.11.3<br>docker tag registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;kube-apiserver-amd64:v1.11.3 k8s.gcr.io&#x2F;kube-apiserver-amd64:v1.11.3<br>docker tag registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;kube-controller-manager-amd64:v1.11.3 k8s.gcr.io&#x2F;kube-controller-manager-amd64:v1.11.3<br>docker tag registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;etcd-amd64:3.2.18 k8s.gcr.io&#x2F;etcd-amd64:3.2.18<br>docker tag registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;pause:3.1 k8s.gcr.io&#x2F;pause:3.1<br>docker tag registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;coredns:1.1.3 k8s.gcr.io&#x2F;coredns:1.1.3<br>docker tag registry.cn-beijing.aliyuncs.com&#x2F;zhoujun&#x2F;pause-amd64:3.1 k8s.gcr.io&#x2F;pause-amd64:3.1<br>ok！</p>
<h3 id="7-flink-docker镜像下载"><a href="#7-flink-docker镜像下载" class="headerlink" title="7.flink docker镜像下载"></a>7.flink docker镜像下载</h3><p>联网，docker pull flink:1.7.2</p>
<h3 id="8-打包docker镜像"><a href="#8-打包docker镜像" class="headerlink" title="8.打包docker镜像"></a>8.打包docker镜像</h3><p>#将镜像存储<br>docker save nginx:latest &gt; &#x2F;root&#x2F;docker-images&#x2F;nginx.tar<br>#导入镜像文件<br>docker load –input &#x2F;root&#x2F;docker-images&#x2F;nginx.tar<br>#通过符号的方式来导入<br>docker load &lt; &#x2F;root&#x2F;docker-images&#x2F;nginx.tar</p>
<h3 id="9-pulled-kubelet-192-168-0-104-Container-image-“flink-1-7”-already-prsent-on-machine"><a href="#9-pulled-kubelet-192-168-0-104-Container-image-“flink-1-7”-already-prsent-on-machine" class="headerlink" title="9.pulled kubelet,192.168.0.104 Container image “flink:1.7” already prsent on machine"></a>9.pulled kubelet,192.168.0.104 Container image “flink:1.7” already prsent on machine</h3><p>pulled kubelet,192.168.0.104 Back-off restarting failed container<br>修改docker.service，在service模块添加参数MountFlags&#x3D;shared， 此参数默认为MountFlags&#x3D;slave</p>
<h3 id="10-pod报错”Back-off-restarting-failed-container”解决办法"><a href="#10-pod报错”Back-off-restarting-failed-container”解决办法" class="headerlink" title="10.pod报错”Back-off restarting failed container”解决办法"></a>10.pod报错”Back-off restarting failed container”解决办法</h3><p>在deployment申明镜像的后面加上命令<br>command: [ “&#x2F;bin&#x2F;bash”, “-ce”, “tail -f &#x2F;dev&#x2F;null” ]</p>
<h3 id="11-kubernetes-v1-2-0进行kubectl-version和kubectl-get-nodes出现localhost-8080-connection-refused的问题"><a href="#11-kubernetes-v1-2-0进行kubectl-version和kubectl-get-nodes出现localhost-8080-connection-refused的问题" class="headerlink" title="11.kubernetes v1.2.0进行kubectl version和kubectl get nodes出现localhost:8080 connection refused的问题"></a>11.kubernetes v1.2.0进行kubectl version和kubectl get nodes出现localhost:8080 connection refused的问题</h3><p>kebuctl -s <a target="_blank" rel="noopener" href="http://apiserverip:8080/">http://apiserverIP:8080</a> version<br>应该可以设置master</p>
<h3 id="12-访问http-localhost-8001-api-v1-namespaces-default-services-flink-jobmanager-ui-proxy-出现"><a href="#12-访问http-localhost-8001-api-v1-namespaces-default-services-flink-jobmanager-ui-proxy-出现" class="headerlink" title="12.访问http://localhost:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy 出现"></a>12.访问<a target="_blank" rel="noopener" href="http://localhost:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy">http://localhost:8001/api/v1/namespaces/default/services/flink-jobmanager:ui/proxy</a> 出现</h3><p>unauthorized</p>
<p>kubectl proxy –address&#x3D;‘192.168.0.104’ -p&#x3D;’8001’ –accept-hosts&#x3D;’^*$’</p>
<h3 id="13-常用命令"><a href="#13-常用命令" class="headerlink" title="13.常用命令"></a>13.常用命令</h3><p>查看服务以及使用的端口<br>kubectl get -n namespace svc<br>kubectl create -f …yaml<br>kubectl describe pod …<br>kubectl get pods -o wide<br>docker image ls<br>kubectl get namespace<br>kubectl get deployment<br>kubectl logs flink-job…</p>
<h3 id="14-task-manager启动报错-java-net-unknownhostexception-flink-jobmanager-temporary-failure-in-name-resolution"><a href="#14-task-manager启动报错-java-net-unknownhostexception-flink-jobmanager-temporary-failure-in-name-resolution" class="headerlink" title="14.task-manager启动报错 java.net.unknownhostexception: flink-jobmanager: temporary failure in name resolution"></a>14.task-manager启动报错 java.net.unknownhostexception: flink-jobmanager: temporary failure in name resolution</h3><p>在kubernetes service文件的spec:中加入clusterIP: 10.0.0.200<br>修改deployment文件中的env: value:flink-jobmanager 10.0.0.200</p>

    </div>

    
    
    

    
      <div>
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      </div>
    
        <div class="reward-container">
  <div>原创技术分享，您的支持将鼓励我继续创作</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/myblog/images/wechatpay.png" alt="秋天以北 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>秋天以北
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://192.168.171.142/myblog/2023/03/02/7-%E5%A4%A7%E6%95%B0%E6%8D%AE/7-flink/k8s%E5%AE%89%E8%A3%85flink/" title="k8s部署flink">http://192.168.171.142/myblog/2023/03/02/7-大数据/7-flink/k8s安装flink/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/images/wechat_channel.jpg">
            <span class="icon">
              <i class="fab fa-weixin"></i>
            </span>

            <span class="label">WeChat</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="/rss2.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/myblog/2023/02/14/9-%E8%BF%90%E7%BB%B4/3-k8s/1-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" rel="prev" title="">
      <i class="fa fa-chevron-left"></i> 
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%89%E8%A3%85%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">安装介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83"><span class="nav-number">2.</span> <span class="nav-text">二、安装环境</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%A6%E6%83%85"><span class="nav-number">2.1.</span> <span class="nav-text">1.服务器详情</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%AE%89%E8%A3%85%E5%8C%85%E8%AF%A6%E6%83%85"><span class="nav-number">2.2.</span> <span class="nav-text">2.安装包详情</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"><span class="nav-number">3.</span> <span class="nav-text">三、安装步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%AE%89%E8%A3%85docker"><span class="nav-number">3.1.</span> <span class="nav-text">1.安装docker</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85"><span class="nav-number">3.1.1.</span> <span class="nav-text">（1）下载安装包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%AE%89%E8%A3%85%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.1.2.</span> <span class="nav-text">（2）安装服务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.1.3.</span> <span class="nav-text">（3）启动服务</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%AE%89%E8%A3%85etcd%E9%9B%86%E7%BE%A4"><span class="nav-number">3.2.</span> <span class="nav-text">2.安装etcd集群</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85-1"><span class="nav-number">3.2.1.</span> <span class="nav-text">（1）下载安装包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%88%9B%E5%BB%BAetcd%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.2.2.</span> <span class="nav-text">（2）创建etcd配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%88%9B%E5%BB%BAetcd%E6%9C%8D%E5%8A%A1%E6%96%87%E4%BB%B6"><span class="nav-number">3.2.3.</span> <span class="nav-text">（3）创建etcd服务文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%90%AF%E5%8A%A8etcd%E9%9B%86%E7%BE%A4"><span class="nav-number">3.2.4.</span> <span class="nav-text">（3）启动etcd集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%884%EF%BC%89%E6%9F%A5%E7%9C%8Betcd%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81"><span class="nav-number">3.2.5.</span> <span class="nav-text">（4）查看etcd集群状态</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E5%AE%89%E8%A3%85kube-apiserver"><span class="nav-number">3.3.</span> <span class="nav-text">3.安装kube-apiserver</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%88%9B%E5%BB%BAkube-apiserver%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.3.1.</span> <span class="nav-text">（1）创建kube-apiserver的配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%88%9B%E5%BB%BAkube-apiserver%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.3.2.</span> <span class="nav-text">（2）创建kube-apiserver服务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%90%AF%E5%8A%A8kube-apiserver%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.3.3.</span> <span class="nav-text">（3）启动kube-apiserver服务</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E5%AE%89%E8%A3%85kube-controller-manager"><span class="nav-number">3.4.</span> <span class="nav-text">4.安装kube-controller-manager</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%88%9B%E5%BB%BAcontroller-manager%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.4.1.</span> <span class="nav-text">（1）创建controller-manager配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%88%9B%E5%BB%BA-controller-manager%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.4.2.</span> <span class="nav-text">（2）创建 controller-manager服务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%90%AF%E5%8A%A8kube-controller-manager%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.4.3.</span> <span class="nav-text">（3）启动kube-controller-manager服务</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E5%AE%89%E8%A3%85kube-scheduler"><span class="nav-number">3.5.</span> <span class="nav-text">5.安装kube-scheduler</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%88%9B%E5%BB%BAkube-controller-manager%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.5.1.</span> <span class="nav-text">（1）创建kube-controller-manager配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%88%9B%E5%BB%BAkube-scheduler%E6%9C%8D%E5%8A%A1%E6%96%87%E4%BB%B6"><span class="nav-number">3.5.2.</span> <span class="nav-text">（2）创建kube-scheduler服务文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%90%AF%E5%8A%A8kube-scheduler%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.5.3.</span> <span class="nav-text">（3）启动kube-scheduler服务</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-%E5%AE%89%E8%A3%85kubelet"><span class="nav-number">3.6.</span> <span class="nav-text">6.安装kubelet</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%88%9B%E5%BB%BAkubeconfig%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.6.1.</span> <span class="nav-text">（1）创建kubeconfig配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%88%9B%E5%BB%BAkubelet%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.6.2.</span> <span class="nav-text">（2）创建kubelet配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%88%9B%E5%BB%BAkubelet%E6%9C%8D%E5%8A%A1%E6%96%87%E4%BB%B6"><span class="nav-number">3.6.3.</span> <span class="nav-text">（3）创建kubelet服务文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%884%EF%BC%89%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1%EF%BC%8C%E5%B9%B6%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8"><span class="nav-number">3.6.4.</span> <span class="nav-text">（4）启动服务，并设置开机启动</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-%E5%AE%89%E8%A3%85kube-proxy"><span class="nav-number">3.7.</span> <span class="nav-text">7.安装kube-proxy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%88%9B%E5%BB%BAproxy%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.7.1.</span> <span class="nav-text">（1）创建proxy配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%88%9B%E5%BB%BAproxy%E6%9C%8D%E5%8A%A1%E6%96%87%E4%BB%B6"><span class="nav-number">3.7.2.</span> <span class="nav-text">（2）创建proxy服务文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1-1"><span class="nav-number">3.7.3.</span> <span class="nav-text">（3）启动服务</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8%EF%BC%8E%E5%AE%89%E8%A3%85flannel"><span class="nav-number">3.8.</span> <span class="nav-text">8．安装flannel</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%88%9B%E5%BB%BA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">3.8.1.</span> <span class="nav-text">（1）创建配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%88%9B%E5%BB%BA%E6%9C%8D%E5%8A%A1%E6%96%87%E4%BB%B6"><span class="nav-number">3.8.2.</span> <span class="nav-text">（2）创建服务文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E9%85%8D%E7%BD%AEetcd"><span class="nav-number">3.8.3.</span> <span class="nav-text">（3）配置etcd</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%884%EF%BC%89%E9%85%8D%E7%BD%AEdocker"><span class="nav-number">3.8.4.</span> <span class="nav-text">（4）配置docker</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%885%EF%BC%89%E5%90%AF%E5%8A%A8%E9%AA%8C%E8%AF%81%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.8.5.</span> <span class="nav-text">（5）启动验证服务</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9%EF%BC%8E%E5%87%86%E5%A4%87docker-flink%E9%95%9C%E5%83%8F"><span class="nav-number">3.9.</span> <span class="nav-text">9．准备docker-flink镜像</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E4%B8%8B%E8%BD%BD%E9%95%9C%E5%83%8F"><span class="nav-number">3.9.1.</span> <span class="nav-text">（1）下载镜像</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E6%9F%A5%E7%9C%8B%E9%95%9C%E5%83%8F"><span class="nav-number">3.9.2.</span> <span class="nav-text">（2）查看镜像</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E9%95%9C%E5%83%8F%E6%89%93%E5%8C%85"><span class="nav-number">3.9.3.</span> <span class="nav-text">（3）镜像打包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%884%EF%BC%89%E9%95%9C%E5%83%8F%E5%AF%BC%E5%85%A5"><span class="nav-number">3.9.4.</span> <span class="nav-text">（4）镜像导入</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10%EF%BC%8Eflink-on-kubernetes%E9%85%8D%E7%BD%AE"><span class="nav-number">3.10.</span> <span class="nav-text">10．flink on kubernetes配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%88%9B%E5%BB%BAkubernetes%E6%9C%8D%E5%8A%A1%E6%96%87%E4%BB%B6"><span class="nav-number">3.10.1.</span> <span class="nav-text">（1）创建kubernetes服务文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E5%90%AF%E5%8A%A8flink%E4%BC%9A%E8%AF%9D%E9%9B%86%E7%BE%A4"><span class="nav-number">3.10.2.</span> <span class="nav-text">（2）启动flink会话集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E5%90%AF%E5%8A%A8service%E7%9A%84%E5%AF%B9%E5%A4%96%E6%9C%8D%E5%8A%A1"><span class="nav-number">3.10.3.</span> <span class="nav-text">（3）启动service的对外服务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%EF%BC%884%EF%BC%89%E8%AE%BF%E9%97%AEflink"><span class="nav-number">3.10.4.</span> <span class="nav-text">（4）访问flink</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86"><span class="nav-number">4.</span> <span class="nav-text">四、报错处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%90%AF%E5%8A%A8etcd%E6%8A%A5%E9%94%99"><span class="nav-number">4.1.</span> <span class="nav-text">1.启动etcd报错</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Etcd%E5%90%AF%E5%8A%A8%E8%8B%A5%E5%87%BA%E7%8E%B0E-rafthttp-request-sent-was-ignored-cluster-ID-mismatch-peer%E2%80%A6-local-x3D-%E2%80%A6"><span class="nav-number">4.2.</span> <span class="nav-text">2.Etcd启动若出现E | rafthttp: request sent was ignored (cluster ID mismatch: peer… local&#x3D;…)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Unable-to-configure-the-docker-daemon-with-file-x2F-etc-x2F-docker-x2F-daemon-json"><span class="nav-number">4.3.</span> <span class="nav-text">3.Unable to configure the docker daemon with file &#x2F;etc&#x2F;docker&#x2F;daemon.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Kubectl-get-pods%E6%97%B6%E6%8A%A5%E9%94%99No-resources-found"><span class="nav-number">4.4.</span> <span class="nav-text">4.Kubectl get pods时报错No resources found</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Warning-MissingClusterDNS"><span class="nav-number">4.5.</span> <span class="nav-text">5.Warning MissingClusterDNS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-Kubernetes%E4%BB%8Ek8s-gcr-io%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98"><span class="nav-number">4.6.</span> <span class="nav-text">6.Kubernetes从k8s.gcr.io拉取镜像失败问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-flink-docker%E9%95%9C%E5%83%8F%E4%B8%8B%E8%BD%BD"><span class="nav-number">4.7.</span> <span class="nav-text">7.flink docker镜像下载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-%E6%89%93%E5%8C%85docker%E9%95%9C%E5%83%8F"><span class="nav-number">4.8.</span> <span class="nav-text">8.打包docker镜像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-pulled-kubelet-192-168-0-104-Container-image-%E2%80%9Cflink-1-7%E2%80%9D-already-prsent-on-machine"><span class="nav-number">4.9.</span> <span class="nav-text">9.pulled kubelet,192.168.0.104 Container image “flink:1.7” already prsent on machine</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-pod%E6%8A%A5%E9%94%99%E2%80%9DBack-off-restarting-failed-container%E2%80%9D%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="nav-number">4.10.</span> <span class="nav-text">10.pod报错”Back-off restarting failed container”解决办法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-kubernetes-v1-2-0%E8%BF%9B%E8%A1%8Ckubectl-version%E5%92%8Ckubectl-get-nodes%E5%87%BA%E7%8E%B0localhost-8080-connection-refused%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">4.11.</span> <span class="nav-text">11.kubernetes v1.2.0进行kubectl version和kubectl get nodes出现localhost:8080 connection refused的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-%E8%AE%BF%E9%97%AEhttp-localhost-8001-api-v1-namespaces-default-services-flink-jobmanager-ui-proxy-%E5%87%BA%E7%8E%B0"><span class="nav-number">4.12.</span> <span class="nav-text">12.访问http:&#x2F;&#x2F;localhost:8001&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;services&#x2F;flink-jobmanager:ui&#x2F;proxy 出现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="nav-number">4.13.</span> <span class="nav-text">13.常用命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-task-manager%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99-java-net-unknownhostexception-flink-jobmanager-temporary-failure-in-name-resolution"><span class="nav-number">4.14.</span> <span class="nav-text">14.task-manager启动报错 java.net.unknownhostexception: flink-jobmanager: temporary failure in name resolution</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="秋天以北"
      src="/myblog/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">秋天以北</p>
  <div class="site-description" itemprop="description">君子博学而日叁醒乎己，则知明而行无过矣</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/myblog/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/myblog/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/myblog/tags/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yourname" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yourname@gmail.com" title="E-Mail → mailto:yourname@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/yourname" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/yourname" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      链接网站
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="/myblog/www.baidu.com" title="www.baidu.com">百度</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">冀ICP备20012268号-1 </a>
      <img src="/myblog/images/batb.png" style="display: inline-block;"><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=%E7%94%B3%E8%AF%B7%E4%B8%AD1" rel="noopener" target="_blank">申请中2 </a>
  </div>

<div class="copyright">
  
  &copy; 2022-08 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">秋天以北</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">231k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">3:30</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset);
            clearInterval(int);
        }
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据
            clearInterval(int); // 停止检测
        }
    }

});
</script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/myblog/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/myblog/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/myblog/lib/velocity/velocity.min.js"></script>
  <script src="/myblog/lib/velocity/velocity.ui.min.js"></script>

<script src="/myblog/js/utils.js"></script>

<script src="/myblog/js/motion.js"></script>


<script src="/myblog/js/schemes/pisces.js"></script>


<script src="/myblog/js/next-boot.js"></script>


  <script defer src="/myblog/lib/three/three.min.js"></script>


  




  
<script src="/myblog/js/local-search.js"></script>













  

  

</body>
</html>
